{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baca FL PAseq735 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-length PAD4 sequence loaded from FASTA:\n",
      "EVKQENRLLNESESSSQGLLGYYFSDLNFQAPMVVTSSTTGDLSIPSSELENIPSENQYFQSAIWSGFIKVKKSDEYTFATSADNHVTMWVDDQEVINKASNSNKIRLEKGRLYQIKIQYQRENPTEKGLDFKLYWTDSQNKKEVISSDNLQLPELKQKSSNSRKKRSTSAGPTVPDRDNDGIPDSLEVEGYTVDVKNKRTFLSPWISNIHEKKGLTKYKSSPEKWSTASDPYSDFEKVTGRIDKNVSPEARHPLVAAYPIVHVDMENIILSKNEDQSTQNTDSETRTISKNTSTSRTHTSEVHGNAEVHASFFDIGGSVSAGFSNSNSSTVAIDHSLSLAGERTWAETMGLNTADTARLNANIRYVNTGTAPIYNVLPTTSLVLGKNQTLATIKAKENQLSQILAPNNYYPSKNLAPIALNAQDDFSSTPITMNYNQFLELEKTKQLRLDTDQVYGNIATYNFENGRVRVDTGSNWSEVLPQIQETTARIIFNGKDLNLVERRIAAVNPSDPLETTKPDMTLKEALKIAFGFNEPNGNLQYQGKDITEFDFNFDQQTSQNIKNQLAELNATNIYTVLDKIKLNAKMNILIRDKRFHYDRNNIAVGADESVVKEAHREVINSSTEGLLLNIDKDIRKILSGYIVEIEDTEGLKEVINDRYDMLNISSLRQDGKTFIDFKKYNDKLPLYISNPNYKVNVYAVTKENTIINPSENGDTSTNGIKKILIFSKKGYEIG\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Function to read the PAD4 sequence from a FASTA file\n",
    "def load_fasta_sequence(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for record in SeqIO.parse(file, \"fasta\"):\n",
    "            return str(record.seq)  # Returns the sequence as a string\n",
    "\n",
    "# Example: Load the PAD4 sequence from a FASTA file\n",
    "fasta_file = \"PAseq735.fasta\"  # Replace with the path to your FASTA file\n",
    "full_length_PAD4 = load_fasta_sequence(fasta_file)\n",
    "\n",
    "# Print the loaded sequence\n",
    "print(\"Full-length PAD4 sequence loaded from FASTA:\")\n",
    "print(full_length_PAD4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_specific_columns(csv_file, columns):\n",
    "    # Membaca kolom tertentu dari file CSV\n",
    "    df = pd.read_csv(csv_file, usecols=columns)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAD4C8 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Peptide  EL-score  BA-score\n",
      "0    FHYDRNNI    0.0027    0.0558\n",
      "1    HYDRNNIA    0.0004    0.0289\n",
      "2    YDRNNIAV    0.0004    0.0316\n",
      "3    DRNNIAVG    0.0000    0.0143\n",
      "4    RNNIAVGA    0.0002    0.0334\n",
      "..        ...       ...       ...\n",
      "128  ILIFSKKG    0.0002    0.0392\n",
      "129  LIFSKKGY    0.0952    0.1801\n",
      "130  IFSKKGYE    0.0002    0.0258\n",
      "131  FSKKGYEI    0.0051    0.0520\n",
      "132  SKKGYEIG    0.0001    0.0169\n",
      "\n",
      "[133 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "csv_file = \"Dataset/csv/PAD4C8BoLA.csv\"\n",
    "columns_to_read = ['Peptide', 'EL-score', 'BA-score']  # Ganti dengan nama kolom yang ingin dibaca\n",
    "df = read_specific_columns(csv_file, columns_to_read)\n",
    "\n",
    "# Menampilkan DataFrame dengan kolom yang dipilih\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAD4C9 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        Peptide  EL-score  BA-score\n",
      "0    FHYDRNNIA    0.0138    0.1028\n",
      "1    HYDRNNIAV    0.0017    0.0468\n",
      "2    YDRNNIAVG    0.0000    0.0268\n",
      "3    DRNNIAVGA    0.0009    0.0301\n",
      "4    RNNIAVGAD    0.0000    0.0282\n",
      "..         ...       ...       ...\n",
      "127  KILIFSKKG    0.0004    0.0485\n",
      "128  ILIFSKKGY    0.1836    0.2640\n",
      "129  LIFSKKGYE    0.0032    0.0912\n",
      "130  IFSKKGYEI    0.0035    0.0567\n",
      "131  FSKKGYEIG    0.0001    0.0311\n",
      "\n",
      "[132 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "csv_file2 = \"Dataset/csv/PAD4C9Bola.csv\"\n",
    "columns_to_read = ['Peptide', 'EL-score', 'BA-score']\n",
    "df2 = read_specific_columns(csv_file2, columns_to_read)\n",
    "\n",
    "# Menampilkan DataFrame dengan kolom yang dipilih\n",
    "print(df2.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pos   Peptide       ID       core     icore  EL-score  EL_Rank  BA-score  \\\n",
      "0    0  FHYDRNNI  PEPLIST  FHYDRN-NI  FHYDRNNI    0.0027  20.0803    0.0558   \n",
      "1    0  HYDRNNIA  PEPLIST  H-YDRNNIA  HYDRNNIA    0.0004  44.5556    0.0289   \n",
      "2    0  YDRNNIAV  PEPLIST  YDR-NNIAV  YDRNNIAV    0.0004  43.5714    0.0316   \n",
      "3    0  DRNNIAVG  PEPLIST  DRNNIAVG-  DRNNIAVG    0.0000  73.7500    0.0143   \n",
      "4    0  RNNIAVGA  PEPLIST  RNN-IAVGA  RNNIAVGA    0.0002  55.0000    0.0334   \n",
      "\n",
      "   BA_Rank     Ave  NB  \n",
      "0  34.2327  0.0027   0  \n",
      "1  68.0273  0.0004   0  \n",
      "2  63.6080  0.0004   0  \n",
      "3  92.1082  0.0000   0  \n",
      "4  60.7318  0.0002   0  \n",
      "   Pos    Peptide       ID       core      icore  EL-score  EL_Rank  BA-score  \\\n",
      "0    0  FHYDRNNIA  PEPLIST  FHYDRNNIA  FHYDRNNIA    0.0138   8.4640    0.1028   \n",
      "1    0  HYDRNNIAV  PEPLIST  HYDRNNIAV  HYDRNNIAV    0.0017  24.9753    0.0468   \n",
      "2    0  YDRNNIAVG  PEPLIST  YDRNNIAVG  YDRNNIAVG    0.0000  74.2500    0.0268   \n",
      "3    0  DRNNIAVGA  PEPLIST  DRNNIAVGA  DRNNIAVGA    0.0009  32.3731    0.0301   \n",
      "4    0  RNNIAVGAD  PEPLIST  RNNIAVGAD  RNNIAVGAD    0.0000  87.5000    0.0282   \n",
      "\n",
      "   BA_Rank     Ave  NB  \n",
      "0  12.4155  0.0138   0  \n",
      "1  42.9978  0.0017   0  \n",
      "2  71.6103  0.0000   0  \n",
      "3  66.1494  0.0009   0  \n",
      "4  69.2798  0.0000   0  \n",
      "[['FHYDRNNI' 0.19613899613899616 0.009323204419889502]\n",
      " ['HYDRNNIA' 0.09227799227799227 0.0013812154696132596]\n",
      " ['YDRNNIAV' 0.10270270270270271 0.0013812154696132596]\n",
      " ['DRNNIAVG' 0.0359073359073359 0.0]\n",
      " ['RNNIAVGA' 0.10965250965250965 0.0006906077348066298]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 3: Load 8mer and 9mer datasets\n",
    "pad4_8mer_df = pd.read_csv('Dataset/csv/PAD4C8BoLA.csv')\n",
    "pad4_9mer_df = pd.read_csv('Dataset/csv/PAD4C9BoLA.csv')\n",
    "\n",
    "# Check dataset structure\n",
    "print(pad4_8mer_df.head())\n",
    "print(pad4_9mer_df.head())\n",
    "\n",
    "# Step 4: Data Preprocessing\n",
    "\n",
    "# Select important columns, assuming 'Peptide' and score columns like 'BA_Score' or 'EL_Score'\n",
    "selected_columns_8mer = ['Peptide', 'BA-score', 'EL-score']\n",
    "selected_columns_9mer = ['Peptide', 'BA-score', 'EL-score']\n",
    "\n",
    "# Extract features (BA_Score, EL_Score) for 8mer and 9mer\n",
    "features_8mer = pad4_8mer_df[selected_columns_8mer]\n",
    "features_9mer = pad4_9mer_df[selected_columns_9mer]\n",
    "\n",
    "# Combine datasets (you can add more if you have 10mer, 11mer, etc.)\n",
    "combined_data = pd.concat([features_8mer, features_9mer], ignore_index=True)\n",
    "\n",
    "# Normalize scores for better VAE performance (Min-Max Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(combined_data[['BA-score', 'EL-score']])\n",
    "\n",
    "# Prepare final dataset\n",
    "peptides = combined_data['Peptide'].values\n",
    "features = np.hstack([peptides.reshape(-1, 1), scaled_features])\n",
    "\n",
    "# Check the preprocessed data\n",
    "print(features[:5])  # Checking first 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment scores (first 5 rows):\n",
      "   Pos   Peptide       ID       core     icore  EL-score  EL_Rank  BA-score  \\\n",
      "0    0  FHYDRNNI  PEPLIST  FHYDRN-NI  FHYDRNNI    0.0027  20.0803    0.0558   \n",
      "1    0  HYDRNNIA  PEPLIST  H-YDRNNIA  HYDRNNIA    0.0004  44.5556    0.0289   \n",
      "2    0  YDRNNIAV  PEPLIST  YDR-NNIAV  YDRNNIAV    0.0004  43.5714    0.0316   \n",
      "3    0  DRNNIAVG  PEPLIST  DRNNIAVG-  DRNNIAVG    0.0000  73.7500    0.0143   \n",
      "4    0  RNNIAVGA  PEPLIST  RNN-IAVGA  RNNIAVGA    0.0002  55.0000    0.0334   \n",
      "\n",
      "   BA_Rank     Ave  NB  \n",
      "0  34.2327  0.0027   0  \n",
      "1  68.0273  0.0004   0  \n",
      "2  63.6080  0.0004   0  \n",
      "3  92.1082  0.0000   0  \n",
      "4  60.7318  0.0002   0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load the CSV file with fragment scores (BA and EL)\n",
    "def load_fragment_scores(csv_file):\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "# Example: Load the 8-12mer fragment scores from a CSV file\n",
    "csv_file = \"Dataset/csv/PAD4C8BoLA.csv\"  # Replace with the path to your CSV file\n",
    "fragment_scores_df = load_fragment_scores(csv_file)\n",
    "\n",
    "# Show the first few rows of the loaded dataset\n",
    "print(\"Fragment scores (first 5 rows):\")\n",
    "print(fragment_scores_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE MODELS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutated fragments (first 5):\n",
      "['THYDQNNC', 'HYTRENTA', 'HSANNIAV', 'GRNNPAVG', 'RNHIAVGW']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to simulate VAE model for generating mutations (simplified)\n",
    "def vae_mutate_fragments(fragments, num_mutations=3):\n",
    "    mutated_fragments = []\n",
    "    for fragment in fragments:\n",
    "        mutated_fragment = list(fragment)\n",
    "        for _ in range(num_mutations):\n",
    "            idx = random.randint(0, len(mutated_fragment)-1)\n",
    "            mutated_fragment[idx] = random.choice(\"ACDEFGHIKLMNPQRSTVWY\")  # Random AA mutation\n",
    "        mutated_fragments.append(\"\".join(mutated_fragment))\n",
    "    return mutated_fragments\n",
    "\n",
    "# Apply VAE to mutate the peptide fragments\n",
    "peptides = fragment_scores_df['Peptide'].tolist()\n",
    "mutated_fragments = vae_mutate_fragments(peptides)\n",
    "\n",
    "# Print the first few mutated fragments\n",
    "print(\"Mutated fragments (first 5):\")\n",
    "print(mutated_fragments[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mutated full-length PAD4 sequence:\n",
      "EVKQENRLLNESESSSQGLLGYYFSDLNFQAPMVVTSSTTGDLSIPSSELENIPSENQYFQSAIWSGFIKVKKSDEYTFATSADNHVTMWVDDQEVINKASNSNKIRLEKGRLYQIKIQYQRENPTEKGLDFKLYWTDSQNKKEVISSDNLQLPELKQKSSNSRKKRSTSAGPTVPDRDNDGIPDSLEVEGYTVDVKNKRTFLSPWISNIHEKKGLTKYKSSPEKWSTASDPYSDFEKVTGRIDKNVSPEARHPLVAAYPIVHVDMENIILSKNEDQSTQNTDSETRTISKNTSTSRTHTSEVHGNAEVHASFFDIGGSVSAGFSNSNSSTVAIDHSLSLAGERTWAETMGLNTADTARLNANIRYVNTGTAPIYNVLPTTSLVLGKNQTLATIKAKENQLSQILAPNNYYPSKNLAPIALNAQDDFSSTPITMNYNQFLELEKTKQLRLDTDQVYGNIATYNFENGRVRVDTGSNWSEVLPQIQETTARIIFNGKDLNLVERRIAAVNPSDPLETTKPDMTLKEALKIAFGFNEPNGNLQYQGKDITEFDFNFDQQTSQNIKNQLAELNATNIYTVLDKIKLNAKMNILIRDKRFHYSDYNIAVGIDQSVVHELHGEVIMSFTEGLLFNIQKDIRAIAGGYTIEIDDTHMLKSVPMDRYDNLSISKLRWDLWTYIDNKKYGDKIDLYISYCNYKHNRYIVAKENTIHNEYENGNRQTQDIKQILRGSKRGYEIG\n"
     ]
    }
   ],
   "source": [
    "# Function to introduce mutations into the full-length sequence based on mutated fragments\n",
    "def mutate_full_length_sequence(full_length_seq, original_fragments, mutated_fragments):\n",
    "    mutated_sequence = full_length_seq\n",
    "    for original, mutated in zip(original_fragments, mutated_fragments):\n",
    "        # Find the original fragment in the full sequence and replace it with the mutated fragment\n",
    "        index = mutated_sequence.find(original)\n",
    "        if index != -1:\n",
    "            mutated_sequence = mutated_sequence[:index] + mutated + mutated_sequence[index+len(original):]\n",
    "    return mutated_sequence\n",
    "\n",
    "# Mutate the full-length PAD4 sequence\n",
    "mutated_full_length_PAD4 = mutate_full_length_sequence(full_length_PAD4, peptides, mutated_fragments)\n",
    "\n",
    "# Print the mutated full-length PAD4 sequence\n",
    "print(\"\\nMutated full-length PAD4 sequence:\")\n",
    "print(mutated_full_length_PAD4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mvae_loss)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Step 5: Train the VAE model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Anthrax Project/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[26], line 44\u001b[0m, in \u001b[0;36mvae_loss\u001b[0;34m(input_peptide, output_vae)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvae_loss\u001b[39m(input_peptide, output_vae):\n\u001b[1;32m     43\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(input_peptide \u001b[38;5;241m-\u001b[39m output_vae))\n\u001b[0;32m---> 44\u001b[0m     kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m z_log_var \u001b[38;5;241m-\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_mean\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mexp(z_log_var)\n\u001b[1;32m     45\u001b[0m     kl_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(kl_loss)\n\u001b[1;32m     46\u001b[0m     kl_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 4: Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features[:, 1:].astype(np.float32))  # Skip the first column (peptide seq)\n",
    "\n",
    "# Encoder\n",
    "input_peptide = layers.Input(shape=(features_scaled.shape[1],))  # Use the scaled features\n",
    "x = layers.Dense(64, activation='relu')(input_peptide)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# Latent space representation\n",
    "latent_dim = 2  # Latent space dimension\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)\n",
    "\n",
    "# Sampling function (updated to avoid TensorFlow issue)\n",
    "def sampling(z_mean, z_log_var):\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(lambda args: sampling(*args))([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "x_decoder = layers.Dense(32, activation='relu')(decoder_input)\n",
    "x_decoder = layers.Dense(64, activation='relu')(x_decoder)\n",
    "output_peptide = layers.Dense(features_scaled.shape[1], activation='sigmoid')(x_decoder)\n",
    "\n",
    "# Define Encoder and Decoder models\n",
    "encoder = models.Model(input_peptide, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = models.Model(decoder_input, output_peptide, name='decoder')\n",
    "\n",
    "# Define VAE model by combining encoder and decoder\n",
    "output_vae = decoder(encoder(input_peptide)[2])\n",
    "vae = models.Model(input_peptide, output_vae)\n",
    "\n",
    "# VAE loss function\n",
    "def vae_loss(input_peptide, output_vae):\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(input_peptide - output_vae))\n",
    "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    kl_loss = tf.reduce_mean(kl_loss)\n",
    "    kl_loss *= -0.5\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "# Step 5: Train the VAE model\n",
    "vae.fit(features_scaled, features_scaled, epochs=50, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
